{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 06: Financial Data Preprocessing Pipeline\n",
    "\n",
    "This notebook creates a comprehensive preprocessing pipeline for financial data, including cleaning, feature engineering, and risk metrics calculation.\n",
    "\n",
    "## Objectives\n",
    "- Clean and validate financial data\n",
    "- Calculate returns and risk metrics\n",
    "- Create technical indicators\n",
    "- Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import utils\n",
    "import cleaning\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"🔧 Financial Data Preprocessing Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch fresh data for preprocessing\n",
    "symbols = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "print(f\"Fetching data for: {symbols}\")\n",
    "\n",
    "raw_data = utils.fetch_multiple_stocks(\n",
    "    symbols=symbols,\n",
    "    prefer_alphavantage=False,\n",
    "    period=\"3mo\"\n",
    ")\n",
    "\n",
    "if not raw_data.empty:\n",
    "    print(f\"✅ Raw data loaded: {raw_data.shape}\")\n",
    "    print(f\"Date range: {raw_data['date'].min()} to {raw_data['date'].max()}\")\n",
    "    print(raw_data.head())\n",
    "else:\n",
    "    print(\"❌ Failed to load data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not raw_data.empty:\n",
    "    # Clean the data using existing cleaning functions\n",
    "    print(\"🧹 Cleaning financial data...\")\n",
    "    \n",
    "    # Fill missing values with median for price columns\n",
    "    price_columns = ['open', 'high', 'low', 'close']\n",
    "    cleaned_data = cleaning.fill_missing_median(raw_data, columns=price_columns)\n",
    "    \n",
    "    # Drop rows with excessive missing data\n",
    "    cleaned_data = cleaning.drop_missing(cleaned_data, threshold=0.5)\n",
    "    \n",
    "    # Normalize volume data\n",
    "    if 'volume' in cleaned_data.columns:\n",
    "        volume_normalized, scaler = cleaning.normalize_data(\n",
    "            cleaned_data, \n",
    "            columns=['volume'], \n",
    "            method='standard'\n",
    "        )\n",
    "        cleaned_data['volume_normalized'] = volume_normalized['volume']\n",
    "    \n",
    "    print(f\"✅ Data cleaned: {cleaned_data.shape}\")\n",
    "    \n",
    "    # Generate cleaning report\n",
    "    cleaning_report = cleaning.generate_cleaning_report(raw_data, cleaned_data)\n",
    "    print(\"\\n📊 Cleaning Report:\")\n",
    "    for key, value in cleaning_report.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Financial Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_financial_features(df):\n",
    "    \"\"\"Create financial features for each symbol.\"\"\"\n",
    "    feature_df = df.copy()\n",
    "    \n",
    "    # Group by symbol for calculations\n",
    "    for symbol in feature_df['symbol'].unique():\n",
    "        mask = feature_df['symbol'] == symbol\n",
    "        symbol_data = feature_df[mask].copy()\n",
    "        \n",
    "        # Calculate returns\n",
    "        symbol_data['daily_return'] = symbol_data['close'].pct_change()\n",
    "        symbol_data['log_return'] = np.log(symbol_data['close'] / symbol_data['close'].shift(1))\n",
    "        \n",
    "        # Calculate moving averages\n",
    "        symbol_data['ma_5'] = symbol_data['close'].rolling(window=5).mean()\n",
    "        symbol_data['ma_20'] = symbol_data['close'].rolling(window=20).mean()\n",
    "        \n",
    "        # Calculate volatility\n",
    "        symbol_data['volatility_10'] = symbol_data['daily_return'].rolling(window=10).std()\n",
    "        symbol_data['volatility_20'] = symbol_data['daily_return'].rolling(window=20).std()\n",
    "        \n",
    "        # Price-based features\n",
    "        symbol_data['high_low_pct'] = (symbol_data['high'] - symbol_data['low']) / symbol_data['low']\n",
    "        symbol_data['open_close_pct'] = (symbol_data['close'] - symbol_data['open']) / symbol_data['open']\n",
    "        \n",
    "        # Update main dataframe\n",
    "        feature_df.loc[mask, symbol_data.columns] = symbol_data\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "if not cleaned_data.empty:\n",
    "    print(\"🔧 Creating financial features...\")\n",
    "    featured_data = create_financial_features(cleaned_data)\n",
    "    \n",
    "    print(f\"✅ Features created: {featured_data.shape}\")\n",
    "    print(f\"New columns: {[col for col in featured_data.columns if col not in cleaned_data.columns]}\")\n",
    "    \n",
    "    # Show sample of features\n",
    "    feature_cols = ['symbol', 'date', 'close', 'daily_return', 'volatility_10', 'ma_5', 'ma_20']\n",
    "    print(\"\\nSample features:\")\n",
    "    print(featured_data[feature_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Risk Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_metrics(df):\n",
    "    \"\"\"Calculate risk metrics for each symbol.\"\"\"\n",
    "    risk_metrics = []\n",
    "    \n",
    "    for symbol in df['symbol'].unique():\n",
    "        symbol_data = df[df['symbol'] == symbol].copy()\n",
    "        returns = symbol_data['daily_return'].dropna()\n",
    "        \n",
    "        if len(returns) > 10:  # Need sufficient data\n",
    "            metrics = {\n",
    "                'symbol': symbol,\n",
    "                'mean_return': returns.mean(),\n",
    "                'volatility': returns.std(),\n",
    "                'annualized_return': returns.mean() * 252,\n",
    "                'annualized_volatility': returns.std() * np.sqrt(252),\n",
    "                'sharpe_ratio': (returns.mean() * 252) / (returns.std() * np.sqrt(252)) if returns.std() > 0 else 0,\n",
    "                'max_return': returns.max(),\n",
    "                'min_return': returns.min(),\n",
    "                'var_95': returns.quantile(0.05),\n",
    "                'skewness': returns.skew(),\n",
    "                'kurtosis': returns.kurtosis()\n",
    "            }\n",
    "            risk_metrics.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(risk_metrics)\n",
    "\n",
    "if not featured_data.empty:\n",
    "    print(\"📊 Calculating risk metrics...\")\n",
    "    risk_summary = calculate_risk_metrics(featured_data)\n",
    "    \n",
    "    print(\"\\n📈 Risk Metrics Summary:\")\n",
    "    print(risk_summary.round(4))\n",
    "    \n",
    "    # Visualize risk metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Annualized returns\n",
    "    axes[0,0].bar(risk_summary['symbol'], risk_summary['annualized_return'])\n",
    "    axes[0,0].set_title('Annualized Returns')\n",
    "    axes[0,0].set_ylabel('Return')\n",
    "    \n",
    "    # Volatility\n",
    "    axes[0,1].bar(risk_summary['symbol'], risk_summary['annualized_volatility'])\n",
    "    axes[0,1].set_title('Annualized Volatility')\n",
    "    axes[0,1].set_ylabel('Volatility')\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    axes[1,0].bar(risk_summary['symbol'], risk_summary['sharpe_ratio'])\n",
    "    axes[1,0].set_title('Sharpe Ratio')\n",
    "    axes[1,0].set_ylabel('Sharpe Ratio')\n",
    "    \n",
    "    # VaR 95%\n",
    "    axes[1,1].bar(risk_summary['symbol'], risk_summary['var_95'])\n",
    "    axes[1,1].set_title('Value at Risk (95%)')\n",
    "    axes[1,1].set_ylabel('VaR')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not featured_data.empty:\n",
    "    # Save processed features\n",
    "    features_path = utils.save_with_timestamp(\n",
    "        df=featured_data,\n",
    "        prefix=\"financial_features\",\n",
    "        source=\"processed\",\n",
    "        ext=\"csv\"\n",
    "    )\n",
    "    \n",
    "    # Save risk metrics\n",
    "    risk_path = utils.save_with_timestamp(\n",
    "        df=risk_summary,\n",
    "        prefix=\"risk_metrics\",\n",
    "        source=\"processed\",\n",
    "        ext=\"csv\"\n",
    "    )\n",
    "    \n",
    "    print(f\"💾 Features saved to: {features_path}\")\n",
    "    print(f\"💾 Risk metrics saved to: {risk_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎯 Stage 06 Summary:\")\n",
    "print(\"✅ Data cleaning completed\")\n",
    "print(\"✅ Financial features engineered\")\n",
    "print(\"✅ Risk metrics calculated\")\n",
    "print(\"✅ Processed data saved\")\n",
    "\n",
    "print(\"\\n📋 Next Steps:\")\n",
    "print(\"- Stage 07: Build risk analysis models\")\n",
    "print(\"- Stage 08: Create portfolio optimization\")\n",
    "print(\"- Stage 09: Deploy and monitor system\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
