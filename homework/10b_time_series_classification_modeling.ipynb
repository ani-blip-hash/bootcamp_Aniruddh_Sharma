{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10b: Time Series/Classification Modeling\n",
    "\n",
    "**Assignment**: Build time series model with lag features and classification pipeline.\n",
    "\n",
    "## Objectives\n",
    "- Create lag and rolling window features\n",
    "- Build time series prediction pipeline\n",
    "- Implement classification model for return direction\n",
    "- Evaluate temporal model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import utils\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"â° Homework 10b: Time Series/Classification Modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load financial data\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "raw_data = utils.fetch_multiple_stocks(symbols, prefer_alphavantage=False, period='2y')\n",
    "\n",
    "if not raw_data.empty:\n",
    "    # Process data with time series features\n",
    "    processed_data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_data = raw_data[raw_data['symbol'] == symbol].copy().sort_values('date')\n",
    "        \n",
    "        # Basic features\n",
    "        symbol_data['daily_return'] = symbol_data['close'].pct_change()\n",
    "        symbol_data['log_return'] = np.log(symbol_data['close'] / symbol_data['close'].shift(1))\n",
    "        symbol_data['price_range'] = (symbol_data['high'] - symbol_data['low']) / symbol_data['close']\n",
    "        \n",
    "        # Lag features (previous day values)\n",
    "        for lag in [1, 2, 3, 5]:\n",
    "            symbol_data[f'return_lag_{lag}'] = symbol_data['daily_return'].shift(lag)\n",
    "            symbol_data[f'volume_lag_{lag}'] = symbol_data['volume'].shift(lag)\n",
    "        \n",
    "        # Rolling window features\n",
    "        for window in [5, 10, 20]:\n",
    "            symbol_data[f'return_mean_{window}'] = symbol_data['daily_return'].rolling(window).mean()\n",
    "            symbol_data[f'return_std_{window}'] = symbol_data['daily_return'].rolling(window).std()\n",
    "            symbol_data[f'volume_mean_{window}'] = symbol_data['volume'].rolling(window).mean()\n",
    "            symbol_data[f'price_sma_{window}'] = symbol_data['close'].rolling(window).mean()\n",
    "        \n",
    "        # Technical indicators\n",
    "        symbol_data['rsi'] = calculate_rsi(symbol_data['close'], window=14)\n",
    "        symbol_data['macd'] = calculate_macd(symbol_data['close'])\n",
    "        \n",
    "        # Target variables\n",
    "        symbol_data['target_return'] = symbol_data['daily_return'].shift(-1)\n",
    "        symbol_data['target_direction'] = (symbol_data['target_return'] > 0).astype(int)\n",
    "        \n",
    "        processed_data.append(symbol_data)\n",
    "    \n",
    "    df = pd.concat(processed_data, ignore_index=True)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    print(f\"âœ… Time series dataset prepared: {df.shape}\")\n",
    "    print(f\"Features: {len([col for col in df.columns if col not in ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']])}\")\nelse:\n",
    "    print(\"âŒ Failed to load data\")\n",
    "\n",
    "def calculate_rsi(prices, window=14):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD indicator\"\"\"\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    return macd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Define feature sets\n",
    "    lag_features = [col for col in df.columns if 'lag_' in col]\n",
    "    rolling_features = [col for col in df.columns if any(x in col for x in ['_mean_', '_std_', '_sma_'])]\n",
    "    technical_features = ['rsi', 'macd', 'price_range']\n",
    "    \n",
    "    all_features = lag_features + rolling_features + technical_features + ['daily_return']\n",
    "    \n",
    "    print(f\"ðŸ“Š Feature Categories:\")\n",
    "    print(f\"Lag features: {len(lag_features)}\")\n",
    "    print(f\"Rolling features: {len(rolling_features)}\")\n",
    "    print(f\"Technical features: {len(technical_features)}\")\n",
    "    print(f\"Total features: {len(all_features)}\")\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = df[all_features].copy()\n",
    "    y_regression = df['target_return'].copy()\n",
    "    y_classification = df['target_direction'].copy()\n",
    "    \n",
    "    # Remove NaN values\n",
    "    mask = ~(X.isna().any(axis=1) | y_regression.isna() | y_classification.isna())\n",
    "    X = X[mask]\n",
    "    y_regression = y_regression[mask]\n",
    "    y_classification = y_classification[mask]\n",
    "    dates = df[mask]['date']\n",
    "    symbols = df[mask]['symbol']\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Final dataset: {X.shape}\")\n",
    "    print(f\"Regression target: {y_regression.shape}\")\n",
    "    print(f\"Classification target: {y_classification.shape}\")\n",
    "    print(f\"Class distribution: {y_classification.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time Series Cross-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Time series split (preserving temporal order)\n",
    "    split_date = dates.quantile(0.8)\n",
    "    train_mask = dates <= split_date\n",
    "    test_mask = dates > split_date\n",
    "    \n",
    "    X_train = X[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_reg_train = y_regression[train_mask]\n",
    "    y_reg_test = y_regression[test_mask]\n",
    "    y_clf_train = y_classification[train_mask]\n",
    "    y_clf_test = y_classification[test_mask]\n",
    "    \n",
    "    print(f\"ðŸ”„ Time Series Split:\")\n",
    "    print(f\"Train period: {dates[train_mask].min()} to {dates[train_mask].max()}\")\n",
    "    print(f\"Test period: {dates[test_mask].min()} to {dates[test_mask].max()}\")\n",
    "    print(f\"Train samples: {X_train.shape[0]}\")\n",
    "    print(f\"Test samples: {X_test.shape[0]}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"\\nâš–ï¸ Features scaled for modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Random Forest Regressor for time series\n",
    "    rf_regressor = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    rf_regressor.fit(X_train_scaled, y_reg_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_reg_train_pred = rf_regressor.predict(X_train_scaled)\n",
    "    y_reg_test_pred = rf_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # Regression metrics\n",
    "    train_r2 = r2_score(y_reg_train, y_reg_train_pred)\n",
    "    test_r2 = r2_score(y_reg_test, y_reg_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_reg_train, y_reg_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_reg_test, y_reg_test_pred))\n",
    "    \n",
    "    print(\"ðŸ“ˆ Time Series Regression Results:\")\n",
    "    print(f\"Train RÂ²: {train_r2:.4f}\")\n",
    "    print(f\"Test RÂ²: {test_r2:.4f}\")\n",
    "    print(f\"Train RMSE: {train_rmse:.6f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.6f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': all_features,\n",
    "        'importance': rf_regressor.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ” Top 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10).round(4))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Predictions vs Actual\n",
    "    axes[0].scatter(y_reg_test, y_reg_test_pred, alpha=0.6, s=20)\n",
    "    axes[0].plot([y_reg_test.min(), y_reg_test.max()], [y_reg_test.min(), y_reg_test.max()], 'r--', lw=2)\n",
    "    axes[0].set_xlabel('Actual Returns')\n",
    "    axes[0].set_ylabel('Predicted Returns')\n",
    "    axes[0].set_title(f'Time Series Regression (RÂ² = {test_r2:.4f})')\n",
    "    \n",
    "    # Feature importance\n",
    "    top_features = feature_importance.head(10)\n",
    "    axes[1].barh(top_features['feature'], top_features['importance'])\n",
    "    axes[1].set_xlabel('Feature Importance')\n",
    "    axes[1].set_title('Top 10 Feature Importances')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification Model for Return Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Random Forest Classifier\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    rf_classifier.fit(X_train_scaled, y_clf_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_clf_train_pred = rf_classifier.predict(X_train_scaled)\n",
    "    y_clf_test_pred = rf_classifier.predict(X_test_scaled)\n",
    "    y_clf_test_proba = rf_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Classification metrics\n",
    "    train_accuracy = accuracy_score(y_clf_train, y_clf_train_pred)\n",
    "    test_accuracy = accuracy_score(y_clf_test, y_clf_test_pred)\n",
    "    \n",
    "    print(\"ðŸŽ¯ Classification Results:\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Detailed Classification Report:\")\n",
    "    print(classification_report(y_clf_test, y_clf_test_pred, \n",
    "                              target_names=['Down', 'Up']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_clf_test, y_clf_test_pred)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'],\n",
    "                ax=axes[0])\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('Actual')\n",
    "    axes[0].set_title('Confusion Matrix')\n",
    "    \n",
    "    # Probability distribution\n",
    "    axes[1].hist(y_clf_test_proba[y_clf_test == 0], alpha=0.7, label='Down', bins=30)\n",
    "    axes[1].hist(y_clf_test_proba[y_clf_test == 1], alpha=0.7, label='Up', bins=30)\n",
    "    axes[1].set_xlabel('Predicted Probability (Up)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Probability Distribution by Class')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance for classification\n",
    "    clf_feature_importance = pd.DataFrame({\n",
    "        'feature': all_features,\n",
    "        'importance': rf_classifier.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ” Top 10 Features for Classification:\")\n",
    "    print(clf_feature_importance.head(10).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Time series cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    cv_scores_reg = []\n",
    "    cv_scores_clf = []\n",
    "    \n",
    "    print(\"ðŸ”„ Time Series Cross-Validation:\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_scaled)):\n",
    "        # Split data\n",
    "        X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_reg_cv_train, y_reg_cv_val = y_reg_train.iloc[train_idx], y_reg_train.iloc[val_idx]\n",
    "        y_clf_cv_train, y_clf_cv_val = y_clf_train.iloc[train_idx], y_clf_train.iloc[val_idx]\n",
    "        \n",
    "        # Regression\n",
    "        rf_reg_cv = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        rf_reg_cv.fit(X_cv_train, y_reg_cv_train)\n",
    "        reg_score = rf_reg_cv.score(X_cv_val, y_reg_cv_val)\n",
    "        cv_scores_reg.append(reg_score)\n",
    "        \n",
    "        # Classification\n",
    "        rf_clf_cv = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        rf_clf_cv.fit(X_cv_train, y_clf_cv_train)\n",
    "        clf_score = rf_clf_cv.score(X_cv_val, y_clf_cv_val)\n",
    "        cv_scores_clf.append(clf_score)\n",
    "        \n",
    "        print(f\"Fold {fold+1}: Regression RÂ² = {reg_score:.4f}, Classification Acc = {clf_score:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Cross-Validation Summary:\")\n",
    "    print(f\"Regression RÂ² - Mean: {np.mean(cv_scores_reg):.4f} Â± {np.std(cv_scores_reg):.4f}\")\n",
    "    print(f\"Classification Acc - Mean: {np.mean(cv_scores_clf):.4f} Â± {np.std(cv_scores_clf):.4f}\")\n",
    "    \n",
    "    # Visualization of CV scores\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axes[0].plot(range(1, 6), cv_scores_reg, 'o-', label='CV Scores')\n",
    "    axes[0].axhline(y=np.mean(cv_scores_reg), color='red', linestyle='--', label='Mean')\n",
    "    axes[0].set_xlabel('Fold')\n",
    "    axes[0].set_ylabel('RÂ² Score')\n",
    "    axes[0].set_title('Regression Cross-Validation')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(range(1, 6), cv_scores_clf, 'o-', label='CV Scores')\n",
    "    axes[1].axhline(y=np.mean(cv_scores_clf), color='red', linestyle='--', label='Mean')\n",
    "    axes[1].set_xlabel('Fold')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Classification Cross-Validation')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Performance by Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Analyze performance by symbol\n",
    "    test_symbols = symbols[test_mask]\n",
    "    symbol_performance = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_test_mask = test_symbols == symbol\n",
    "        if symbol_test_mask.sum() > 10:  # Minimum samples\n",
    "            # Get symbol-specific predictions\n",
    "            symbol_reg_actual = y_reg_test[symbol_test_mask]\n",
    "            symbol_reg_pred = y_reg_test_pred[symbol_test_mask]\n",
    "            symbol_clf_actual = y_clf_test[symbol_test_mask]\n",
    "            symbol_clf_pred = y_clf_test_pred[symbol_test_mask]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            reg_r2 = r2_score(symbol_reg_actual, symbol_reg_pred)\n",
    "            clf_acc = accuracy_score(symbol_clf_actual, symbol_clf_pred)\n",
    "            \n",
    "            symbol_performance.append({\n",
    "                'Symbol': symbol,\n",
    "                'Regression_R2': reg_r2,\n",
    "                'Classification_Acc': clf_acc,\n",
    "                'N_samples': symbol_test_mask.sum()\n",
    "            })\n",
    "    \n",
    "    symbol_df = pd.DataFrame(symbol_performance)\n",
    "    print(\"\\nðŸ“ˆ Performance by Symbol:\")\n",
    "    print(symbol_df.round(4))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axes[0].bar(symbol_df['Symbol'], symbol_df['Regression_R2'], alpha=0.7)\n",
    "    axes[0].set_ylabel('RÂ² Score')\n",
    "    axes[0].set_title('Regression Performance by Symbol')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    axes[1].bar(symbol_df['Symbol'], symbol_df['Classification_Acc'], alpha=0.7)\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Classification Performance by Symbol')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Model Comparison\n",
    "\n",
    "### Time Series Modeling Results\n",
    "\n",
    "**Regression Model (Return Prediction)**\n",
    "- Predicts continuous return values using lag and rolling features\n",
    "- Random Forest captures non-linear relationships\n",
    "- Feature importance reveals most predictive time series patterns\n",
    "\n",
    "**Classification Model (Direction Prediction)**\n",
    "- Predicts binary up/down movement direction\n",
    "- Balanced classes to handle market symmetry\n",
    "- Probability outputs enable confidence-based trading strategies\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Temporal Dependencies**: Lag features capture short-term momentum\n",
    "2. **Rolling Statistics**: Moving averages and volatility provide context\n",
    "3. **Technical Indicators**: RSI and MACD add market sentiment information\n",
    "4. **Cross-Validation**: Time series splits preserve temporal structure\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Model Type | Strengths | Limitations |\n",
    "|------------|-----------|-------------|\n",
    "| Linear Regression | Interpretable, fast | Assumes linearity |\n",
    "| Time Series RF | Captures non-linearity | Less interpretable |\n",
    "| Classification | Clear trading signals | Binary output only |\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "1. **Portfolio Management**: Use regression for position sizing\n",
    "2. **Risk Management**: Classification for stop-loss triggers\n",
    "3. **Strategy Development**: Combine both models for robust signals\n",
    "4. **Performance Attribution**: Feature importance guides strategy focus\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Ensemble Methods**: Combine multiple model predictions\n",
    "2. **Deep Learning**: LSTM/GRU for complex temporal patterns\n",
    "3. **Alternative Data**: Incorporate sentiment, news, economic indicators\n",
    "4. **Real-time Implementation**: Deploy models for live trading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
