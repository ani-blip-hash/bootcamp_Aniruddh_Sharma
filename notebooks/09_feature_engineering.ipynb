{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 09: Feature Engineering\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the feature engineering process for bike demand prediction, creating meaningful features to improve model performance based on domain knowledge and EDA insights.\n",
    "\n",
    "## Feature Engineering Strategy\n",
    "Based on our EDA findings, we'll create features in the following categories:\n",
    "1. **Temporal Features**: Hour patterns, weekend effects, cyclical time\n",
    "2. **Weather Features**: Temperature-humidity interactions, comfort indices\n",
    "3. **Derived Features**: Rolling averages, lag features, rate of change\n",
    "4. **Interaction Features**: Complex relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and feature engineering module\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from feature_engineering import (\n",
    "    feature_engineering_pipeline,\n",
    "    create_temporal_features,\n",
    "    create_weather_features,\n",
    "    create_derived_features,\n",
    "    get_feature_importance_summary\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üîß Feature Engineering Libraries Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "data = pd.read_csv('../data/sample-data.csv')\n",
    "\n",
    "print(\"üìä Original Dataset:\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Columns: {data.columns.tolist()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Temporal Feature Engineering\n",
    "\n",
    "### Rationale:\n",
    "- **Hour Categories**: Bike demand follows daily patterns (morning commute, lunch, evening)\n",
    "- **Weekend Indicator**: Usage patterns differ between weekdays and weekends\n",
    "- **Cyclical Encoding**: Hour is cyclical (23 is close to 0), sin/cos captures this\n",
    "- **Rush Hours**: Peak demand during commuting hours (7-9 AM, 5-7 PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features\n",
    "data_temporal = create_temporal_features(data)\n",
    "\n",
    "print(\"‚è∞ Temporal Features Created:\")\n",
    "temporal_features = ['hour_category', 'is_weekend', 'hour_sin', 'hour_cos', \n",
    "                    'is_morning_rush', 'is_evening_rush', 'is_work_hours']\n",
    "\n",
    "for feature in temporal_features:\n",
    "    print(f\"   ‚Ä¢ {feature}: {data_temporal[feature].dtype}\")\n",
    "\n",
    "# Visualize temporal patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Hour categories vs demand\n",
    "sns.boxplot(data=data_temporal, x='hour_category', y='demand', ax=axes[0,0])\n",
    "axes[0,0].set_title('Demand by Hour Category')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Weekend vs weekday demand\n",
    "sns.boxplot(data=data_temporal, x='is_weekend', y='demand', ax=axes[0,1])\n",
    "axes[0,1].set_title('Demand: Weekday (0) vs Weekend (1)')\n",
    "\n",
    "# Cyclical hour encoding\n",
    "scatter = axes[1,0].scatter(data_temporal['hour_sin'], data_temporal['hour_cos'], \n",
    "                          c=data_temporal['demand'], cmap='viridis')\n",
    "axes[1,0].set_title('Cyclical Hour Encoding (colored by demand)')\n",
    "axes[1,0].set_xlabel('Hour Sin')\n",
    "axes[1,0].set_ylabel('Hour Cos')\n",
    "plt.colorbar(scatter, ax=axes[1,0])\n",
    "\n",
    "# Rush hour effects\n",
    "rush_data = data_temporal.groupby('hour')['demand'].mean().reset_index()\n",
    "axes[1,1].plot(rush_data['hour'], rush_data['demand'], marker='o')\n",
    "axes[1,1].axvspan(7, 9, alpha=0.3, color='red', label='Morning Rush')\n",
    "axes[1,1].axvspan(17, 19, alpha=0.3, color='blue', label='Evening Rush')\n",
    "axes[1,1].set_title('Demand by Hour with Rush Hour Highlights')\n",
    "axes[1,1].set_xlabel('Hour')\n",
    "axes[1,1].set_ylabel('Average Demand')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weather Feature Engineering\n",
    "\n",
    "### Rationale:\n",
    "- **Temperature-Humidity Interaction**: Combined effect on comfort\n",
    "- **Weather Comfort Index**: Optimal biking conditions around 20-25¬∞C, 40-60% humidity\n",
    "- **Temperature Categories**: Non-linear relationship with demand\n",
    "- **Weather Extremes**: Very hot/cold or humid conditions deter biking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weather features\n",
    "data_weather = create_weather_features(data_temporal)\n",
    "\n",
    "print(\"üå°Ô∏è Weather Features Created:\")\n",
    "weather_features = ['temp_humidity_interaction', 'weather_comfort_index', \n",
    "                   'temperature_category', 'humidity_category', \n",
    "                   'is_temp_extreme', 'is_humidity_extreme', 'is_ideal_weather']\n",
    "\n",
    "for feature in weather_features:\n",
    "    if feature in data_weather.columns:\n",
    "        print(f\"   ‚Ä¢ {feature}: {data_weather[feature].dtype}\")\n",
    "\n",
    "# Visualize weather features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Weather comfort index vs demand\n",
    "axes[0,0].scatter(data_weather['weather_comfort_index'], data_weather['demand'], alpha=0.7)\n",
    "axes[0,0].set_title('Demand vs Weather Comfort Index')\n",
    "axes[0,0].set_xlabel('Weather Comfort Index')\n",
    "axes[0,0].set_ylabel('Demand')\n",
    "\n",
    "# Temperature categories vs demand\n",
    "sns.boxplot(data=data_weather, x='temperature_category', y='demand', ax=axes[0,1])\n",
    "axes[0,1].set_title('Demand by Temperature Category')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Humidity categories vs demand\n",
    "sns.boxplot(data=data_weather, x='humidity_category', y='demand', ax=axes[1,0])\n",
    "axes[1,0].set_title('Demand by Humidity Category')\n",
    "\n",
    "# Ideal weather conditions\n",
    "sns.boxplot(data=data_weather, x='is_ideal_weather', y='demand', ax=axes[1,1])\n",
    "axes[1,1].set_title('Demand: Non-ideal (0) vs Ideal Weather (1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print weather comfort statistics\n",
    "print(\"\\nüìä Weather Comfort Analysis:\")\n",
    "comfort_stats = data_weather.groupby('is_ideal_weather')['demand'].agg(['mean', 'std', 'count'])\n",
    "print(comfort_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Derived Features (Time Series)\n",
    "\n",
    "### Rationale:\n",
    "- **Rolling Averages**: Smooth out noise, capture trends\n",
    "- **Lag Features**: Previous demand influences current demand\n",
    "- **Rate of Change**: Momentum in weather and demand patterns\n",
    "- **Moving Statistics**: Capture local patterns and variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived features\n",
    "data_derived = create_derived_features(data_weather)\n",
    "\n",
    "print(\"üìà Derived Features Created:\")\n",
    "derived_features = ['demand_rolling_3h', 'demand_rolling_std_3h', 'demand_rolling_6h',\n",
    "                   'demand_lag_1', 'demand_lag_2', 'temperature_change', \n",
    "                   'humidity_change', 'demand_change', 'demand_momentum']\n",
    "\n",
    "for feature in derived_features:\n",
    "    if feature in data_derived.columns:\n",
    "        print(f\"   ‚Ä¢ {feature}: {data_derived[feature].dtype}\")\n",
    "\n",
    "# Visualize derived features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Demand vs rolling average\n",
    "axes[0,0].plot(data_derived.index, data_derived['demand'], label='Actual Demand', alpha=0.7)\n",
    "axes[0,0].plot(data_derived.index, data_derived['demand_rolling_3h'], \n",
    "               label='3-Hour Rolling Average', linewidth=2)\n",
    "axes[0,0].set_title('Demand vs Rolling Average')\n",
    "axes[0,0].set_xlabel('Time Index')\n",
    "axes[0,0].set_ylabel('Demand')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Lag feature correlation\n",
    "axes[0,1].scatter(data_derived['demand_lag_1'], data_derived['demand'], alpha=0.7)\n",
    "axes[0,1].set_title('Current vs Previous Hour Demand')\n",
    "axes[0,1].set_xlabel('Previous Hour Demand')\n",
    "axes[0,1].set_ylabel('Current Demand')\n",
    "\n",
    "# Temperature change vs demand change\n",
    "axes[1,0].scatter(data_derived['temperature_change'], data_derived['demand_change'], alpha=0.7)\n",
    "axes[1,0].set_title('Temperature Change vs Demand Change')\n",
    "axes[1,0].set_xlabel('Temperature Change')\n",
    "axes[1,0].set_ylabel('Demand Change')\n",
    "\n",
    "# Demand momentum\n",
    "axes[1,1].plot(data_derived.index, data_derived['demand_momentum'], alpha=0.7)\n",
    "axes[1,1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1,1].set_title('Demand Momentum (Acceleration)')\n",
    "axes[1,1].set_xlabel('Time Index')\n",
    "axes[1,1].set_ylabel('Demand Momentum')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Feature Engineering Pipeline\n",
    "\n",
    "Apply all feature engineering steps using the pipeline function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply complete feature engineering pipeline\n",
    "engineered_data = feature_engineering_pipeline(data)\n",
    "\n",
    "print(f\"\\nüìä Feature Engineering Summary:\")\n",
    "print(f\"   Original features: {data.shape[1]}\")\n",
    "print(f\"   Engineered features: {engineered_data.shape[1] - data.shape[1]}\")\n",
    "print(f\"   Total features: {engineered_data.shape[1]}\")\n",
    "print(f\"   Data points: {engineered_data.shape[0]}\")\n",
    "\n",
    "# Display feature categories\n",
    "print(\"\\nüè∑Ô∏è Feature Categories:\")\n",
    "all_features = engineered_data.columns.tolist()\n",
    "\n",
    "original_features = ['hour', 'temperature', 'humidity', 'day_of_week', 'demand']\n",
    "temporal_features = [f for f in all_features if any(x in f for x in ['hour_', 'weekend', 'rush', 'work'])]\n",
    "weather_features = [f for f in all_features if any(x in f for x in ['temp_', 'humidity_', 'weather_', 'ideal'])]\n",
    "derived_features = [f for f in all_features if any(x in f for x in ['rolling', 'lag', 'change', 'momentum'])]\n",
    "interaction_features = [f for f in all_features if 'interaction' in f or 'combo' in f]\n",
    "\n",
    "print(f\"   ‚Ä¢ Original: {len(original_features)} features\")\n",
    "print(f\"   ‚Ä¢ Temporal: {len(temporal_features)} features\")\n",
    "print(f\"   ‚Ä¢ Weather: {len(weather_features)} features\")\n",
    "print(f\"   ‚Ä¢ Derived: {len(derived_features)} features\")\n",
    "print(f\"   ‚Ä¢ Interaction: {len(interaction_features)} features\")\n",
    "print(f\"   ‚Ä¢ One-hot encoded: {engineered_data.shape[1] - len(original_features) - len(temporal_features) - len(weather_features) - len(derived_features) - len(interaction_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance based on correlation with target\n",
    "importance_df = get_feature_importance_summary(engineered_data)\n",
    "\n",
    "print(\"üèÜ Top 15 Most Important Features:\")\n",
    "print(importance_df.head(15))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['abs_correlation'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Absolute Correlation with Demand')\n",
    "plt.title('Top 20 Feature Importance (by Correlation)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance by category\n",
    "print(\"\\nüìä Feature Importance by Category:\")\n",
    "for feature in importance_df.head(10)['feature']:\n",
    "    if any(x in feature for x in ['hour_', 'weekend', 'rush', 'work']):\n",
    "        category = 'Temporal'\n",
    "    elif any(x in feature for x in ['temp', 'humidity', 'weather', 'ideal']):\n",
    "        category = 'Weather'\n",
    "    elif any(x in feature for x in ['rolling', 'lag', 'change', 'momentum']):\n",
    "        category = 'Derived'\n",
    "    elif 'interaction' in feature:\n",
    "        category = 'Interaction'\n",
    "    else:\n",
    "        category = 'Original/Other'\n",
    "    \n",
    "    corr = importance_df[importance_df['feature'] == feature]['abs_correlation'].iloc[0]\n",
    "    print(f\"   {category:12} | {feature:25} | {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering Insights and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of top features\n",
    "top_feature_names = importance_df.head(15)['feature'].tolist() + ['demand']\n",
    "top_features_data = engineered_data[top_feature_names]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = top_features_data.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix: Top 15 Features + Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature engineering validation\n",
    "print(\"\\n‚úÖ Feature Engineering Validation:\")\n",
    "print(f\"   ‚Ä¢ No missing values: {engineered_data.isnull().sum().sum() == 0}\")\n",
    "print(f\"   ‚Ä¢ All features numeric: {len(engineered_data.select_dtypes(include=[np.number]).columns) == len(engineered_data.columns)}\")\n",
    "print(f\"   ‚Ä¢ Feature variance > 0: {(engineered_data.var() > 0).all()}\")\n",
    "print(f\"   ‚Ä¢ No infinite values: {np.isfinite(engineered_data.select_dtypes(include=[np.number])).all().all()}\")\n",
    "\n",
    "# Data quality check\n",
    "print(\"\\nüîç Data Quality Summary:\")\n",
    "print(f\"   ‚Ä¢ Shape: {engineered_data.shape}\")\n",
    "print(f\"   ‚Ä¢ Memory usage: {engineered_data.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "print(f\"   ‚Ä¢ Duplicate rows: {engineered_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered dataset\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create processed data directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save main engineered dataset\n",
    "engineered_data.to_csv('../data/processed/engineered_features.csv', index=False)\n",
    "\n",
    "# Save feature importance\n",
    "importance_df.to_csv('../data/processed/feature_importance.csv', index=False)\n",
    "\n",
    "# Save feature metadata\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "metadata_file = f'../data/processed/feature_metadata_{timestamp}.txt'\n",
    "\n",
    "with open(metadata_file, 'w') as f:\n",
    "    f.write(\"FEATURE ENGINEERING METADATA\\n\")\n",
    "    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Original features: {len(original_features)}\\n\")\n",
    "    f.write(f\"Engineered features: {engineered_data.shape[1] - len(original_features)}\\n\")\n",
    "    f.write(f\"Total features: {engineered_data.shape[1]}\\n\")\n",
    "    f.write(f\"Data points: {engineered_data.shape[0]}\\n\\n\")\n",
    "    \n",
    "    f.write(\"FEATURE CATEGORIES:\\n\")\n",
    "    f.write(f\"‚Ä¢ Temporal: {len(temporal_features)}\\n\")\n",
    "    f.write(f\"‚Ä¢ Weather: {len(weather_features)}\\n\")\n",
    "    f.write(f\"‚Ä¢ Derived: {len(derived_features)}\\n\")\n",
    "    f.write(f\"‚Ä¢ Interaction: {len(interaction_features)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 10 FEATURES:\\n\")\n",
    "    for i, row in importance_df.head(10).iterrows():\n",
    "        f.write(f\"{row['importance_rank']:2d}. {row['feature']:30s} ({row['abs_correlation']:.3f})\\n\")\n",
    "\n",
    "print(\"üíæ Files Saved:\")\n",
    "print(f\"   ‚Ä¢ Engineered features: ../data/processed/engineered_features.csv\")\n",
    "print(f\"   ‚Ä¢ Feature importance: ../data/processed/feature_importance.csv\")\n",
    "print(f\"   ‚Ä¢ Metadata: {metadata_file}\")\n",
    "\n",
    "print(f\"\\nüéØ Feature Engineering Complete!\")\n",
    "print(f\"   Ready for model training with {engineered_data.shape[1]} features\")\n",
    "print(f\"   Top predictor: {importance_df.iloc[0]['feature']} (r={importance_df.iloc[0]['abs_correlation']:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
