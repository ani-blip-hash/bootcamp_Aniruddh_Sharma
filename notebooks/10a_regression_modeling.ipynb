{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 10a: Regression Modeling for Bike Demand Prediction\n",
    "\n",
    "## Overview\n",
    "Comprehensive regression modeling approach for bike demand prediction with time-aware splitting, feature selection, assumption validation, and risk-aware interpretation.\n",
    "\n",
    "## Modeling Approach: Regression\n",
    "**Rationale**: Bike demand is continuous numerical target, making regression most appropriate for predicting exact rental counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "print(\"ü§ñ Libraries Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "try:\n",
    "    data = pd.read_csv('../data/processed/engineered_features.csv')\nexcept FileNotFoundError:\n",
    "    from feature_engineering import feature_engineering_pipeline\n",
    "    raw_data = pd.read_csv('../data/sample-data.csv')\n",
    "    data = feature_engineering_pipeline(raw_data)\n",
    "    data.to_csv('../data/processed/engineered_features.csv', index=False)\n",
    "\n",
    "print(f\"üìä Dataset: {data.shape}\")\n",
    "print(f\"Target range: {data['demand'].min()}-{data['demand'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Selection & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target leakage features\n",
    "y = data['demand'].copy()\n",
    "leakage_features = ['demand', 'demand_rolling_3h', 'demand_rolling_6h', \n",
    "                   'demand_lag_1', 'demand_lag_2', 'demand_change']\n",
    "X = data.drop(columns=[col for col in leakage_features if col in data.columns])\n",
    "\n",
    "print(f\"üéØ Target: demand\")\n",
    "print(f\"üö´ Removed {len([col for col in leakage_features if col in data.columns])} leakage features\")\n",
    "print(f\"üìä Features: {X.shape[1]}\")\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"‚ö†Ô∏è Filled missing values\")\nelse:\n",
    "    print(\"‚úÖ No missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection - top 15 features\n",
    "k_best = min(15, X.shape[1])\n",
    "selector = SelectKBest(score_func=f_regression, k=k_best)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "selected_features = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "print(f\"üèÜ Selected {k_best} top features:\")\n",
    "feature_scores = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'f_score': selector.scores_,\n",
    "    'selected': selector.get_support()\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "print(feature_scores.head(10))\n",
    "X = X[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time-Aware Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-aware split (80/20)\n",
    "n_samples = len(X)\n",
    "train_size = int(0.8 * n_samples)\n",
    "\n",
    "X_train = X.iloc[:train_size].copy()\n",
    "X_test = X.iloc[train_size:].copy()\n",
    "y_train = y.iloc[:train_size].copy()\n",
    "y_test = y.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"üìä Time-Aware Split:\")\n",
    "print(f\"   Training: {X_train.shape[0]} samples ({X_train.shape[0]/n_samples*100:.1f}%)\")\n",
    "print(f\"   Test: {X_test.shape[0]} samples ({X_test.shape[0]/n_samples*100:.1f}%)\")\n",
    "print(f\"   No temporal overlap: {X_train.index.max() < X_test.index.min()}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"üìè Features scaled (StandardScaler)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso Regression': Lasso(alpha=0.1, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(\"ü§ñ Training Models:\")\n",
    "for name, model in models.items():\n",
    "    # Use scaled features for linear models\n",
    "    if 'Forest' in name:\n",
    "        X_tr, X_te = X_train, X_test\n",
    "    else:\n",
    "        X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "    \n",
    "    model.fit(X_tr, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    y_pred_train = model.predict(X_tr)\n",
    "    y_pred_test = model.predict(X_te)\n",
    "    \n",
    "    results[name] = {\n",
    "        'train_r2': r2_score(y_train, y_pred_train),\n",
    "        'test_r2': r2_score(y_test, y_pred_test),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "        'predictions': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   {name}: R¬≤={results[name]['test_r2']:.3f}, RMSE={results[name]['test_rmse']:.2f}\")\n",
    "\n",
    "# Best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['test_r2'])\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (R¬≤={results[best_model_name]['test_r2']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Diagnostic Plots & Assumption Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on best linear model for diagnostics\n",
    "linear_models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression']\n",
    "best_linear = max([m for m in linear_models if m in results], \n",
    "                 key=lambda k: results[k]['test_r2'])\n",
    "\n",
    "model = trained_models[best_linear]\n",
    "y_pred = results[best_linear]['predictions']\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "print(f\"üîç Diagnostic Analysis: {best_linear}\")\n",
    "print(f\"   Residual mean: {residuals.mean():.6f} (should be ~0)\")\n",
    "print(f\"   Residual std: {residuals.std():.3f}\")\n",
    "\n",
    "# Diagnostic plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Residuals vs Fitted\n",
    "axes[0,0].scatter(y_pred, residuals, alpha=0.7)\n",
    "axes[0,0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0,0].set_title('Residuals vs Fitted')\n",
    "axes[0,0].set_xlabel('Fitted Values')\n",
    "axes[0,0].set_ylabel('Residuals')\n",
    "\n",
    "# Q-Q Plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[0,1])\n",
    "axes[0,1].set_title('Q-Q Plot (Normality Check)')\n",
    "\n",
    "# Residuals histogram\n",
    "axes[1,0].hist(residuals, bins=10, alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_title('Residuals Distribution')\n",
    "axes[1,0].set_xlabel('Residuals')\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[1,1].scatter(y_test, y_pred, alpha=0.7)\n",
    "axes[1,1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1,1].set_title('Actual vs Predicted')\n",
    "axes[1,1].set_xlabel('Actual')\n",
    "axes[1,1].set_ylabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance & Coefficients Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coefficients for best linear model\n",
    "if hasattr(trained_models[best_linear], 'coef_'):\n",
    "    coefficients = pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'coefficient': trained_models[best_linear].coef_\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(f\"üîç {best_linear} Coefficients:\")\n",
    "    print(coefficients.head(10))\n",
    "    \n",
    "    # Plot top coefficients\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_coef = coefficients.head(10)\n",
    "    colors = ['red' if x < 0 else 'blue' for x in top_coef['coefficient']]\n",
    "    plt.barh(range(len(top_coef)), top_coef['coefficient'], color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(top_coef)), top_coef['feature'])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.title(f'Top 10 Feature Coefficients - {best_linear}')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Random Forest feature importance\n",
    "if 'Random Forest' in trained_models:\n",
    "    rf_importance = pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'importance': trained_models['Random Forest'].feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüå≥ Random Forest Feature Importance:\")\n",
    "    print(rf_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Interpretation & Risk Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance summary\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test_R2': [results[m]['test_r2'] for m in results.keys()],\n",
    "    'Test_RMSE': [results[m]['test_rmse'] for m in results.keys()],\n",
    "    'Test_MAE': [results[m]['test_mae'] for m in results.keys()],\n",
    "    'Overfitting': [results[m]['train_r2'] - results[m]['test_r2'] for m in results.keys()]\n",
    "}).sort_values('Test_R2', ascending=False)\n",
    "\n",
    "print(\"üìä Model Performance Summary:\")\n",
    "print(performance_df.round(3))\n",
    "\n",
    "print(f\"\\nüéØ Key Insights:\")\n",
    "print(f\"   ‚Ä¢ Best model explains {results[best_model_name]['test_r2']:.1%} of demand variance\")\n",
    "print(f\"   ‚Ä¢ Average prediction error: {results[best_model_name]['test_rmse']:.1f} bikes\")\n",
    "print(f\"   ‚Ä¢ Mean absolute error: {results[best_model_name]['test_mae']:.1f} bikes\")\n",
    "\n",
    "# Risk assessment\n",
    "print(f\"\\n‚ö†Ô∏è Risk Assessment:\")\n",
    "max_error = abs(residuals).max()\n",
    "print(f\"   ‚Ä¢ Maximum prediction error: {max_error:.1f} bikes\")\n",
    "print(f\"   ‚Ä¢ 95% of errors within: ¬±{np.percentile(abs(residuals), 95):.1f} bikes\")\n",
    "print(f\"   ‚Ä¢ Model reliability: {'High' if results[best_model_name]['test_r2'] > 0.8 else 'Moderate' if results[best_model_name]['test_r2'] > 0.6 else 'Low'}\")\n",
    "\n",
    "# Business interpretation\n",
    "demand_range = y.max() - y.min()\n",
    "relative_error = results[best_model_name]['test_rmse'] / demand_range\n",
    "print(f\"   ‚Ä¢ Relative error: {relative_error:.1%} of demand range\")\n",
    "print(f\"   ‚Ä¢ Suitable for: {'Operational planning' if relative_error < 0.15 else 'Strategic planning only'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'predicted': results[best_model_name]['predictions'],\n",
    "    'residuals': residuals\n",
    "})\n",
    "predictions_df.to_csv('../data/processed/model_predictions.csv', index=False)\n",
    "\n",
    "# Save model summary\n",
    "performance_df.to_csv('../data/processed/model_performance.csv', index=False)\n",
    "\n",
    "print(\"üíæ Results saved:\")\n",
    "print(\"   ‚Ä¢ Model predictions: ../data/processed/model_predictions.csv\")\n",
    "print(\"   ‚Ä¢ Performance summary: ../data/processed/model_performance.csv\")\n",
    "print(f\"\\nüéØ Modeling Complete! Best model: {best_model_name} (R¬≤={results[best_model_name]['test_r2']:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
