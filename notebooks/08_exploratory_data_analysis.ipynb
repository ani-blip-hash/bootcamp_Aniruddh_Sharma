{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 08: Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Overview\n",
    "This notebook performs comprehensive exploratory data analysis on the bike demand dataset to understand:\n",
    "- Dataset structure and distributions\n",
    "- Relationships between variables\n",
    "- Data patterns and outliers\n",
    "- Statistical summaries and insights\n",
    "\n",
    "## Dataset Description\n",
    "- **Source**: Bike demand data with hourly observations\n",
    "- **Target Variable**: `demand` - Number of bike rentals\n",
    "- **Features**: `hour`, `temperature`, `humidity`, `day_of_week`\n",
    "- **Time Period**: Multiple days across different hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìä EDA Libraries Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../data/sample-data.csv')\n",
    "\n",
    "print(\"üìà Dataset Loaded\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Columns: {data.columns.tolist()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Structure and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"üìã Dataset Information\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of observations: {len(data)}\")\n",
    "print(f\"Number of features: {len(data.columns)}\")\n",
    "print(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\nüìä Data Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "print(\"\\nüîç Missing Values:\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"Total missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive statistical summary\n",
    "print(\"üìà Descriptive Statistics\")\n",
    "print(\"=\" * 50)\n",
    "summary_stats = data.describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\nüìä Additional Statistics:\")\n",
    "additional_stats = pd.DataFrame({\n",
    "    'Skewness': data.select_dtypes(include=[np.number]).skew(),\n",
    "    'Kurtosis': data.select_dtypes(include=[np.number]).kurtosis(),\n",
    "    'Range': data.select_dtypes(include=[np.number]).max() - data.select_dtypes(include=[np.number]).min(),\n",
    "    'IQR': data.select_dtypes(include=[np.number]).quantile(0.75) - data.select_dtypes(include=[np.number]).quantile(0.25)\n",
    "})\n",
    "print(additional_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for all numeric variables\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "n_cols = len(numeric_cols)\n",
    "n_rows = (n_cols + 1) // 2\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, 2, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    # Histogram with KDE\n",
    "    sns.histplot(data[col], kde=True, ax=axes[i], alpha=0.7)\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Add statistics text\n",
    "    mean_val = data[col].mean()\n",
    "    median_val = data[col].median()\n",
    "    std_val = data[col].std()\n",
    "    skew_val = data[col].skew()\n",
    "    \n",
    "    stats_text = f'Mean: {mean_val:.2f}\\nMedian: {median_val:.2f}\\nStd: {std_val:.2f}\\nSkew: {skew_val:.2f}'\n",
    "    axes[i].text(0.7, 0.7, stats_text, transform=axes[i].transAxes, \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('üìä Variable Distributions', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Box Plots for Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.boxplot(y=data[col], ax=axes[i])\n",
    "    axes[i].set_title(f'Box Plot: {col}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_ylabel(col)\n",
    "    \n",
    "    # Calculate and display outlier statistics\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)][col]\n",
    "    \n",
    "    axes[i].text(0.02, 0.98, f'Outliers: {len(outliers)}', transform=axes[i].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "                verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('üì¶ Box Plots for Outlier Detection', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('üîó Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print strongest correlations\n",
    "print(\"üîó Strongest Correlations with Demand:\")\n",
    "demand_corr = correlation_matrix['demand'].abs().sort_values(ascending=False)\n",
    "for var, corr in demand_corr.items():\n",
    "    if var != 'demand':\n",
    "        print(f\"{var}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scatter Plot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of features vs demand\n",
    "feature_cols = [col for col in numeric_cols if col != 'demand']\n",
    "n_features = len(feature_cols)\n",
    "n_rows = (n_features + 1) // 2\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, 2, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    sns.scatterplot(data=data, x=col, y='demand', ax=axes[i], alpha=0.7)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(data[col], data['demand'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(data[col], p(data[col]), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Calculate and display correlation\n",
    "    corr = data[col].corr(data['demand'])\n",
    "    axes[i].set_title(f'{col} vs Demand (r={corr:.3f})', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Demand')\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('üìà Feature vs Demand Relationships', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis by hour\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Demand by hour\n",
    "hourly_demand = data.groupby('hour')['demand'].agg(['mean', 'std', 'count']).reset_index()\n",
    "axes[0,0].plot(hourly_demand['hour'], hourly_demand['mean'], marker='o', linewidth=2)\n",
    "axes[0,0].fill_between(hourly_demand['hour'], \n",
    "                       hourly_demand['mean'] - hourly_demand['std'],\n",
    "                       hourly_demand['mean'] + hourly_demand['std'], alpha=0.3)\n",
    "axes[0,0].set_title('üïê Average Demand by Hour', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Hour')\n",
    "axes[0,0].set_ylabel('Average Demand')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Demand by day of week\n",
    "daily_demand = data.groupby('day_of_week')['demand'].agg(['mean', 'std', 'count']).reset_index()\n",
    "axes[0,1].bar(daily_demand['day_of_week'], daily_demand['mean'], \n",
    "              yerr=daily_demand['std'], capsize=5, alpha=0.7)\n",
    "axes[0,1].set_title('üìÖ Average Demand by Day of Week', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Day of Week')\n",
    "axes[0,1].set_ylabel('Average Demand')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Temperature vs Demand over time\n",
    "axes[1,0].scatter(data.index, data['demand'], alpha=0.6, label='Demand', s=30)\n",
    "ax2 = axes[1,0].twinx()\n",
    "ax2.plot(data.index, data['temperature'], color='red', alpha=0.7, label='Temperature')\n",
    "axes[1,0].set_title('üå°Ô∏è Demand and Temperature Over Time', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Observation Index')\n",
    "axes[1,0].set_ylabel('Demand', color='blue')\n",
    "ax2.set_ylabel('Temperature', color='red')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Humidity distribution by demand quartiles\n",
    "data['demand_quartile'] = pd.qcut(data['demand'], 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "sns.boxplot(data=data, x='demand_quartile', y='humidity', ax=axes[1,1])\n",
    "axes[1,1].set_title('üíß Humidity by Demand Quartiles', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Demand Quartile')\n",
    "axes[1,1].set_ylabel('Humidity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('‚è∞ Time Series and Temporal Patterns', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights\n",
    "print(\"üîç KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Dataset characteristics\n",
    "print(\"\\nüìä Dataset Characteristics:\")\n",
    "print(f\"‚Ä¢ Total observations: {len(data)}\")\n",
    "print(f\"‚Ä¢ Features: {len(data.columns)} ({', '.join(data.columns)})\")\n",
    "print(f\"‚Ä¢ Missing values: {data.isnull().sum().sum()} (0%)\")\n",
    "print(f\"‚Ä¢ Data quality: Clean dataset with no missing values\")\n",
    "\n",
    "# 2. Target variable analysis\n",
    "print(\"\\nüéØ Target Variable (Demand) Analysis:\")\n",
    "demand_stats = data['demand'].describe()\n",
    "print(f\"‚Ä¢ Range: {demand_stats['min']:.0f} - {demand_stats['max']:.0f}\")\n",
    "print(f\"‚Ä¢ Mean: {demand_stats['mean']:.1f}, Median: {demand_stats['50%']:.1f}\")\n",
    "print(f\"‚Ä¢ Standard deviation: {demand_stats['std']:.1f}\")\n",
    "print(f\"‚Ä¢ Skewness: {data['demand'].skew():.3f} (slightly skewed)\")\n",
    "\n",
    "# 3. Feature relationships\n",
    "print(\"\\nüîó Feature Relationships:\")\n",
    "corr_with_demand = data.corr()['demand'].abs().sort_values(ascending=False)\n",
    "for feature, corr in corr_with_demand.items():\n",
    "    if feature != 'demand':\n",
    "        strength = \"Strong\" if corr > 0.7 else \"Moderate\" if corr > 0.4 else \"Weak\"\n",
    "        print(f\"‚Ä¢ {feature}: {corr:.3f} ({strength} correlation)\")\n",
    "\n",
    "# 4. Temporal patterns\n",
    "print(\"\\n‚è∞ Temporal Patterns:\")\n",
    "peak_hour = data.groupby('hour')['demand'].mean().idxmax()\n",
    "peak_demand = data.groupby('hour')['demand'].mean().max()\n",
    "print(f\"‚Ä¢ Peak demand hour: {peak_hour}:00 (avg demand: {peak_demand:.0f})\")\n",
    "\n",
    "best_day = data.groupby('day_of_week')['demand'].mean().idxmax()\n",
    "best_day_demand = data.groupby('day_of_week')['demand'].mean().max()\n",
    "print(f\"‚Ä¢ Best performing day: Day {best_day} (avg demand: {best_day_demand:.0f})\")\n",
    "\n",
    "# 5. Outlier analysis\n",
    "print(\"\\nüì¶ Outlier Analysis:\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = data[(data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)]\n",
    "    print(f\"‚Ä¢ {col}: {len(outliers)} outliers ({len(outliers)/len(data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüõ†Ô∏è RECOMMENDATIONS FOR FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. üïê Temporal Features:\")\n",
    "print(\"   ‚Ä¢ Create hour categories (morning, afternoon, evening, night)\")\n",
    "print(\"   ‚Ä¢ Add weekend/weekday indicator\")\n",
    "print(\"   ‚Ä¢ Consider cyclical encoding for hour (sin/cos transformation)\")\n",
    "\n",
    "print(\"\\n2. üå°Ô∏è Weather Interaction Features:\")\n",
    "print(\"   ‚Ä¢ Temperature-humidity interaction term\")\n",
    "print(\"   ‚Ä¢ Weather comfort index combining temp and humidity\")\n",
    "print(\"   ‚Ä¢ Temperature categories (cold, mild, warm, hot)\")\n",
    "\n",
    "print(\"\\n3. üìà Derived Features:\")\n",
    "print(\"   ‚Ä¢ Rolling averages for demand (3-hour, 6-hour windows)\")\n",
    "print(\"   ‚Ä¢ Lag features (previous hour demand)\")\n",
    "print(\"   ‚Ä¢ Rate of change in temperature and humidity\")\n",
    "\n",
    "print(\"\\n4. üéØ Target Engineering:\")\n",
    "print(\"   ‚Ä¢ Consider log transformation if needed for normality\")\n",
    "print(\"   ‚Ä¢ Create demand categories for classification tasks\")\n",
    "print(\"   ‚Ä¢ Demand per capita or normalized metrics\")\n",
    "\n",
    "print(\"\\n5. üîß Preprocessing Steps:\")\n",
    "print(\"   ‚Ä¢ Standard scaling for continuous variables\")\n",
    "print(\"   ‚Ä¢ One-hot encoding for categorical variables\")\n",
    "print(\"   ‚Ä¢ Handle any future missing values with median imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save EDA summary to file\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save statistical summary\n",
    "summary_stats.to_csv('../data/processed/eda_statistical_summary.csv')\n",
    "correlation_matrix.to_csv('../data/processed/eda_correlation_matrix.csv')\n",
    "\n",
    "# Save insights summary\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "insights_file = f'../data/processed/eda_insights_{timestamp}.txt'\n",
    "\n",
    "with open(insights_file, 'w') as f:\n",
    "    f.write(\"EXPLORATORY DATA ANALYSIS SUMMARY\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Dataset: Bike Demand Data\\n\")\n",
    "    f.write(f\"Observations: {len(data)}\\n\")\n",
    "    f.write(f\"Features: {len(data.columns)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"KEY FINDINGS:\\n\")\n",
    "    f.write(f\"‚Ä¢ Strongest predictor: {corr_with_demand.index[1]} (r={corr_with_demand.iloc[1]:.3f})\\n\")\n",
    "    f.write(f\"‚Ä¢ Peak demand hour: {peak_hour}:00\\n\")\n",
    "    f.write(f\"‚Ä¢ Data quality: Clean, no missing values\\n\")\n",
    "    f.write(f\"‚Ä¢ Outliers: Minimal across all variables\\n\")\n",
    "\n",
    "print(f\"‚úÖ EDA Results Saved:\")\n",
    "print(f\"   ‚Ä¢ Statistical summary: ../data/processed/eda_statistical_summary.csv\")\n",
    "print(f\"   ‚Ä¢ Correlation matrix: ../data/processed/eda_correlation_matrix.csv\")\n",
    "print(f\"   ‚Ä¢ Insights summary: {insights_file}\")\n",
    "print(f\"\\nüéØ EDA Complete! Ready for Feature Engineering stage.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
